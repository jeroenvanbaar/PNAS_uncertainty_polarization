{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:09.701711Z",
     "start_time": "2021-02-16T19:45:07.461549Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os, sys, glob, scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nilearn, nibabel, nltools, nistats\n",
    "from nltools.data import Brain_Data\n",
    "from nistats.reporting import get_clusters_table\n",
    "from nilearn.plotting import plot_stat_map, plot_roi, plot_img, plot_glass_brain\n",
    "from nilearn.input_data import NiftiMasker\n",
    "from nibabel.nifti1 import Nifti1Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:09.707307Z",
     "start_time": "2021-02-16T19:45:09.703070Z"
    }
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.realpath('../../..')\n",
    "print(base_dir)\n",
    "results_dir = os.path.realpath('../../../Results/voxelwise_ISRSA/nifti')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:09.714004Z",
     "start_time": "2021-02-16T19:45:09.708816Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_clusters(image, stat_threshold = 0, extent_threshold = 0, sort_by_size = False, include_peaks_only = True):\n",
    "    \n",
    "    # Compute negative image\n",
    "    neg_image_arr = -(image.get_data().copy())\n",
    "    neg_image = Nifti1Image(neg_image_arr, image.affine.copy())\n",
    "    \n",
    "    # Find clusters\n",
    "    clusters = get_clusters_table(image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    clusters = clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters = get_clusters_table(neg_image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    neg_clusters = neg_clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters['peak_value'] = -neg_clusters['peak_value']\n",
    "    \n",
    "    # Append pos and neg\n",
    "    clusters = clusters.append(neg_clusters)\n",
    "    clusters['abs_peak_value'] = clusters['peak_value'].apply(np.abs)\n",
    "    clusters = clusters.sort_values(by='abs_peak_value', ascending = False)\n",
    "    \n",
    "    # Get peaks\n",
    "    if include_peaks_only:\n",
    "        peaks = clusters.copy()\n",
    "        peaks = peaks.loc[peaks['ID'].apply(lambda x: not str(x)[-1].isalpha()),:].reset_index(drop=True)\n",
    "        if sort_by_size:\n",
    "            peaks = peaks.sort_values(by = 'size', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    return clusters, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:09.719980Z",
     "start_time": "2021-02-16T19:45:09.715415Z"
    }
   },
   "outputs": [],
   "source": [
    "def xyz_to_ijk(MNI, image):\n",
    "    return list(np.linalg.inv(image.affine[:3,:3]).dot(MNI-image.affine[:3,3]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:09.726509Z",
     "start_time": "2021-02-16T19:45:09.721330Z"
    }
   },
   "outputs": [],
   "source": [
    "def expand_cluster(image, cluster_peak_MNI, verbose = True):\n",
    "    \n",
    "    # Find IJK of peak\n",
    "    i,j,k = xyz_to_ijk(cluster_peak_MNI,image)\n",
    "    cluster_peak_IJK = [i,j,k]\n",
    "    if verbose: print('MNI: %s, IJK: %s'%(cluster_peak_MNI, cluster_peak_IJK))\n",
    "    \n",
    "    # Double check that peak value is correct\n",
    "    peakval = image.get_data()[i][j][k]\n",
    "    if verbose: print('Peak value extracted from image data array: %f'%peakval)\n",
    "    \n",
    "    # Binarize image\n",
    "    binarized = (image.get_data() != 0).astype(int)\n",
    "        \n",
    "    # Label each cluster with a different number, reserve 0 for empty voxels\n",
    "    conn_mat = np.zeros((3, 3, 3), int)  # 6-connectivity, aka NN1 or \"faces\"\n",
    "    conn_mat[1, 1, :] = 1\n",
    "    conn_mat[1, :, 1] = 1\n",
    "    conn_mat[:, 1, 1] = 1\n",
    "    label_map = scipy.ndimage.measurements.label(binarized, conn_mat)[0]\n",
    "    clust_image = nibabel.Nifti1Image(label_map, affine=image.affine)\n",
    "    \n",
    "    # Find voxels with same label as cluster peak\n",
    "    cluster_label = clust_image.get_data()[i,j,k]\n",
    "    cluster_ROI = (clust_image.get_data() == cluster_label).astype(int)\n",
    "    ROI_mask = nibabel.Nifti1Image(cluster_ROI, affine = image.affine)\n",
    "    if verbose: print('Cluster ROI located')\n",
    "    if verbose: print('Cluster size as extracted from image data array: %i voxels = %i mm^3'%(\n",
    "        sum(cluster_ROI.flatten()),sum(cluster_ROI.flatten())*8))\n",
    "    \n",
    "    return cluster_peak_IJK, cluster_ROI, ROI_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select effect of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:10.311304Z",
     "start_time": "2021-02-16T19:45:10.309086Z"
    }
   },
   "outputs": [],
   "source": [
    "run = 3\n",
    "filter_TR = False\n",
    "TR_start = 1\n",
    "TR_end = 711\n",
    "model = 'ideology'\n",
    "term = 'scale(ideology_similarity)'\n",
    "threshold = 'thr-pval-fdr-0.05'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:10.782438Z",
     "start_time": "2021-02-16T19:45:10.776144Z"
    }
   },
   "outputs": [],
   "source": [
    "run_model_dir = ('run-%i_TRs-%i-%i_model-%s'%(run,TR_start,TR_end,model) \n",
    "                     if filter_TR else 'run-%i_model-%s'%(run,model))\n",
    "fpath = glob.glob('%s/%s/*%s*%s*.nii.gz'%(results_dir, run_model_dir, term, threshold))[0]\n",
    "print(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:11.470335Z",
     "start_time": "2021-02-16T19:45:11.453260Z"
    }
   },
   "outputs": [],
   "source": [
    "image = nilearn.image.load_img(fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:12.717451Z",
     "start_time": "2021-02-16T19:45:11.717677Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plot_stat_map(image, colorbar=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:14.608591Z",
     "start_time": "2021-02-16T19:45:12.720185Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_stat_map(image, cut_coords=np.arange(-60,1,10), display_mode = 'x', colorbar = False)\n",
    "plot_stat_map(image, cut_coords=np.arange(0,61,10), display_mode = 'x', colorbar = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:18.082829Z",
     "start_time": "2021-02-16T19:45:17.464227Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_k = 5\n",
    "clusters, peaks = get_clusters(image, 0, min_k)\n",
    "display(peaks.head())\n",
    "print(peaks.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:39.898244Z",
     "start_time": "2021-02-16T19:45:20.284796Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_n = np.shape(peaks)[0]\n",
    "if plot_n < 30:\n",
    "    fig, ax = plt.subplots(nrows = plot_n, ncols = 1, figsize = [8,plot_n*2])\n",
    "    for clust_i, row in peaks.iterrows():\n",
    "        vmax = 2\n",
    "        plot_stat_map(image, cut_coords = row[['X','Y','Z']].values.flatten(),\n",
    "                      axes = ax[clust_i], cmap = 'RdBu_r', vmax = vmax, colorbar = False)\n",
    "        ax[clust_i].set(title = 'Cluster ID %i, %imm^3'%(row['ID'],row['size']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find cluster locations and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:41.982363Z",
     "start_time": "2021-02-16T19:45:39.899916Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cluster_list = peaks['ID'].unique()\n",
    "ROIs = dict()\n",
    "for ID in cluster_list:\n",
    "    print(ID, end = ',')\n",
    "    cluster_info = peaks.query('ID == @ID')\n",
    "#     display(cluster_info)\n",
    "    cluster_peak_MNI = list(cluster_info.iloc[0].loc[['X','Y','Z']].values.flatten())\n",
    "    cluster_peak_IJK, cluster_voxels, cluster_mask = expand_cluster(image, cluster_peak_MNI)\n",
    "    ROIs[ID] = {'peak_IJK':cluster_peak_IJK,'mask':cluster_mask}\n",
    "ROIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and compute inter-subject correlation values from mean cluster signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:41.986667Z",
     "start_time": "2021-02-16T19:45:41.984026Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_sub_funx(sub, run, nifti_dir = \"/gpfs_home/jvanbaar/data/jvanbaar/polarization/derivatives/cleaning\"):\n",
    "    fname = nifti_dir + '/sub-%03d'%sub + '/ses-1/func/' + \\\n",
    "            'sub-%03d_ses-1_task-videoWatching_run-%i'%(sub,run) + \\\n",
    "            '_space-MNI152NLin2009cAsym_desc-cleaned_bold.nii.gz'\n",
    "    sub_funx = nilearn.image.load_img(fname)\n",
    "    return sub_funx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:41.994860Z",
     "start_time": "2021-02-16T19:45:41.988294Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_sub_cluster_data(sub_funx, cluster_peak_IJK, cluster_mask,\n",
    "                            return_peak_data = True,\n",
    "                            return_mean_cluster_data = True,\n",
    "                            return_full_cluster_data = False):\n",
    "    \n",
    "    return_dict = {}\n",
    "    \n",
    "    # Get values at peak\n",
    "    if return_peak_data:\n",
    "        i,j,k = cluster_peak_IJK\n",
    "        peak_data = sub_funx.get_data()[i,j,k]\n",
    "        peak_data = pd.DataFrame(peak_data, columns=['peak_BOLD']).reset_index()\n",
    "        peak_data = peak_data.rename(columns = {'index':'TR'})\n",
    "        peak_data['sub'] = sub\n",
    "        peak_data['cluster'] = ID\n",
    "        peak_data = peak_data[['sub','cluster','TR','peak_BOLD']]\n",
    "        return_dict['peak_data'] = peak_data\n",
    "    \n",
    "    # Get cluster data\n",
    "    if return_mean_cluster_data or return_full_cluster_data:\n",
    "        roi_masker = NiftiMasker(mask_img=cluster_mask).fit()\n",
    "        voxels_signals = roi_masker.transform(sub_funx)\n",
    "    \n",
    "    # Take mean across voxels\n",
    "    if return_mean_cluster_data:\n",
    "        mean_cluster_dat = pd.DataFrame(voxels_signals.mean(1)).reset_index()\n",
    "        mean_cluster_dat = mean_cluster_dat.rename(columns = {'index':'TR',0:'mean_BOLD'})\n",
    "        mean_cluster_dat['sub'] = sub\n",
    "        mean_cluster_dat['cluster'] = ID\n",
    "        mean_cluster_dat = mean_cluster_dat[['sub','cluster','TR','mean_BOLD']]\n",
    "        return_dict['mean_cluster_data'] = mean_cluster_dat\n",
    "    \n",
    "    # Return all voxel data\n",
    "    if return_full_cluster_data:\n",
    "        full_cluster_dat = pd.DataFrame(voxels_signals).melt(var_name = 'voxel', value_name = 'BOLD').reset_index()\n",
    "        full_cluster_dat = full_cluster_dat.rename(columns = {'index':'TR'})\n",
    "        full_cluster_dat['sub'] = sub\n",
    "        full_cluster_dat['cluster'] = ID\n",
    "        full_cluster_dat = full_cluster_dat[['sub','cluster','voxel','TR','BOLD']]\n",
    "        return_dict['full_cluster_data'] = full_cluster_dat\n",
    "    \n",
    "    return return_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:42.015636Z",
     "start_time": "2021-02-16T19:45:42.004278Z"
    }
   },
   "outputs": [],
   "source": [
    "all_subs = pd.read_csv(base_dir + '/Data/Subjects_and_exclusions/all_subjects.csv')['sub'].values.tolist()\n",
    "print(len(all_subs))\n",
    "\n",
    "# Exclusions\n",
    "exclude = pd.read_csv(base_dir + '/Data/Subjects_and_exclusions/exclude_video-watching_aggregate_run-%i.csv'%run)[\n",
    "    'sub'].values.tolist()\n",
    "if run == 1:\n",
    "    last_TR = 390\n",
    "elif run == 2:\n",
    "    last_TR = 307\n",
    "elif run == 3:\n",
    "    last_TR = 720\n",
    "print('Exclusions: %s'%exclude)\n",
    "subs_keep = [i for i in all_subs if i not in exclude]\n",
    "print('Keep %i subjects'%len(subs_keep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:07.452634Z",
     "start_time": "2021-02-16T19:45:50.080200Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_ROI_dat = pd.DataFrame()\n",
    "for sub in subs_keep:\n",
    "    print('Loading data subject %i run %i...'%(sub,run))\n",
    "    sub_funx = load_sub_funx(sub, run)\n",
    "    print('Extracting cluster data... ', end = '')\n",
    "    for ID in list(ROIs.keys()):\n",
    "        print(ID, end = ', ')\n",
    "        [cluster_peak_IJK, cluster_mask] = [ROIs[ID][i] for i in ['peak_IJK','mask']]\n",
    "        out = extract_sub_cluster_data(sub_funx, cluster_peak_IJK, cluster_mask, return_mean_cluster_data=True)\n",
    "        all_ROI_dat = all_ROI_dat.append(out['mean_cluster_data'].merge(out['peak_data'])).reset_index(drop=True)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:07.472877Z",
     "start_time": "2021-02-16T20:30:07.460658Z"
    }
   },
   "outputs": [],
   "source": [
    "display(all_ROI_dat.head())\n",
    "print(all_ROI_dat.shape)\n",
    "print(all_ROI_dat['sub'].unique())\n",
    "print(all_ROI_dat['cluster'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T19:45:42.026359Z",
     "start_time": "2021-02-16T19:45:42.022402Z"
    }
   },
   "outputs": [],
   "source": [
    "results_dir + '/' + run_model_dir "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:09.571147Z",
     "start_time": "2021-02-16T20:30:07.474343Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ROI_dat.to_csv(results_dir + '/' + run_model_dir + \n",
    "                    '/ROI_data_term-%s.csv'%term, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute inter-subject correlations and store data for dyadic regression at the ROI level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:09.791018Z",
     "start_time": "2021-02-16T20:30:09.572608Z"
    }
   },
   "outputs": [],
   "source": [
    "all_ROI_dat = pd.read_csv(results_dir + '/' + run_model_dir + \n",
    "                    '/ROI_data_term-%s.csv'%term, index_col = None)\n",
    "all_ROI_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:10.343355Z",
     "start_time": "2021-02-16T20:30:09.792367Z"
    }
   },
   "outputs": [],
   "source": [
    "out_var = 'mean_BOLD'\n",
    "for IDi,ID in enumerate(sorted(all_ROI_dat['cluster'].unique())):\n",
    "    print(ID, end = ', ')\n",
    "    ISC_dat = all_ROI_dat.query('cluster == @ID and TR > 3 and TR < @last_TR').pivot_table(\n",
    "        index = ['TR'], values = [out_var], columns = 'sub')\n",
    "    subcolumns = [i[1] for i in ISC_dat.columns.tolist()]\n",
    "    ISC = 1 - pd.DataFrame(scipy.spatial.distance.squareform(\n",
    "                        scipy.spatial.distance.pdist(ISC_dat.T, metric = 'correlation')),\n",
    "                       columns = subcolumns)\n",
    "    ISC['sub'] = subcolumns\n",
    "    ISC = ISC.melt(id_vars = 'sub', var_name = 'sub2', value_name = 'ISC.ROI.%i'%ID)\n",
    "    ISC = ISC.rename(columns = {'sub2':'SubID1','sub':'SubID2'})\n",
    "    if IDi == 0:\n",
    "        all_ISC = ISC.copy()\n",
    "    else:\n",
    "        all_ISC = all_ISC.merge(ISC, on = ['SubID1','SubID2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:10.355051Z",
     "start_time": "2021-02-16T20:30:10.344466Z"
    }
   },
   "outputs": [],
   "source": [
    "predictor_RDMs = pd.read_csv(base_dir + '/Data/Cleaned/Surveys/predictor_RDMs_4.csv', index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:10.390847Z",
     "start_time": "2021-02-16T20:30:10.356058Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_dat = predictor_RDMs[['SubID1','SubID2','ideology_similarity','joint_IUS',\n",
    "                             'age_distance','scan_day_distance','same_gender',\n",
    "                             'same_undergrad','same_community']]\n",
    "reg_dat = reg_dat.merge(all_ISC, on = ['SubID1','SubID2'])\n",
    "reg_dat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-02-16T20:30:10.446472Z",
     "start_time": "2021-02-16T20:30:10.392439Z"
    }
   },
   "outputs": [],
   "source": [
    "reg_dat.to_csv(results_dir + '/' + run_model_dir + \n",
    "                    '/ROI_regression_data_term-%s_%s.csv'%(term,out_var), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
