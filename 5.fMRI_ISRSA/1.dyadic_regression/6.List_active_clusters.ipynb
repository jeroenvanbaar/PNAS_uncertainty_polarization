{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nilearn, nibabel, nltools\n",
    "from nltools.data import Brain_Data\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map, plot_img, plot_roi\n",
    "from nilearn.image import new_img_like\n",
    "from nistats.reporting import get_clusters_table\n",
    "from nibabel.nifti1 import Nifti1Image\n",
    "import nibabel as nib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(image, stat_threshold = 0, extent_threshold = 0, sort_by_size = False, include_peaks_only = True):\n",
    "    \n",
    "    # Compute negative image\n",
    "    neg_image_arr = -(image.get_data().copy())\n",
    "    neg_image = Nifti1Image(neg_image_arr, image.affine.copy())\n",
    "    \n",
    "    # Find clusters\n",
    "    clusters = get_clusters_table(image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    clusters = clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters = get_clusters_table(neg_image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    neg_clusters = neg_clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters['peak_value'] = -neg_clusters['peak_value']\n",
    "    \n",
    "    # Append pos and neg\n",
    "    clusters = clusters.append(neg_clusters)\n",
    "    clusters['abs_peak_value'] = clusters['peak_value'].apply(np.abs)\n",
    "    clusters = clusters.sort_values(by='abs_peak_value', ascending = False)\n",
    "    \n",
    "    # Get peaks\n",
    "    if include_peaks_only:\n",
    "        peaks = clusters.copy()\n",
    "        peaks = peaks.loc[peaks['ID'].apply(lambda x: not str(x)[-1].isalpha()),:].reset_index(drop=True)\n",
    "        if sort_by_size:\n",
    "            peaks = peaks.sort_values(by = 'size', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    return clusters, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_to_ijk(MNI, image):\n",
    "    return list(np.linalg.inv(image.affine[:3,:3]).dot(MNI-image.affine[:3,3]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cluster(image, cluster_peak_MNI, verbose = True):\n",
    "    \n",
    "    # Find IJK of peak\n",
    "    i,j,k = xyz_to_ijk(cluster_peak_MNI,image)\n",
    "    cluster_peak_IJK = [i,j,k]\n",
    "    if verbose: print('MNI: %s, IJK: %s'%(cluster_peak_MNI, cluster_peak_IJK))\n",
    "    \n",
    "    # Double check that peak value is correct\n",
    "    peakval = image.get_data()[i][j][k]\n",
    "    if verbose: print('Peak value extracted from image data array: %f'%peakval)\n",
    "    \n",
    "    # Binarize image\n",
    "    binarized = (image.get_data() != 0).astype(int)\n",
    "        \n",
    "    # Label each cluster with a different number, reserve 0 for empty voxels\n",
    "    conn_mat = np.zeros((3, 3, 3), int)  # 6-connectivity, aka NN1 or \"faces\"\n",
    "    conn_mat[1, 1, :] = 1\n",
    "    conn_mat[1, :, 1] = 1\n",
    "    conn_mat[:, 1, 1] = 1\n",
    "    label_map = scipy.ndimage.measurements.label(binarized, conn_mat)[0]\n",
    "    clust_image = nibabel.Nifti1Image(label_map, affine=image.affine)\n",
    "    \n",
    "    # Find voxels with same label as cluster peak\n",
    "    cluster_label = clust_image.get_data()[i,j,k]\n",
    "    cluster_ROI = (clust_image.get_data() == cluster_label).astype(int)\n",
    "    ROI_mask = nibabel.Nifti1Image(cluster_ROI, affine = image.affine)\n",
    "    if verbose: print('Cluster ROI located')\n",
    "    if verbose: print('Cluster size as extracted from image data array: %i voxels = %i mm^3'%(\n",
    "        sum(cluster_ROI.flatten()),sum(cluster_ROI.flatten())*8))\n",
    "    \n",
    "    return cluster_peak_IJK, cluster_ROI, ROI_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_extent_threshold(fname, extent_threshold, verbose = False):\n",
    "    \n",
    "    print('Loading stat map...')\n",
    "    beta_map = nilearn.image.load_img(fname)\n",
    "    beta_map_arr = beta_map.get_data()\n",
    "\n",
    "    print('Preparing thresholded mask...')\n",
    "    all_cluster_mask_arr = beta_map_arr.copy().astype(int)\n",
    "    all_cluster_mask_arr[:] = 0\n",
    "\n",
    "    print('Counting clusters...')\n",
    "    clusters, peaks = get_clusters(beta_map, threshold = 0,\n",
    "                               extent_threshold = extent_threshold, include_peaks_only = True)\n",
    "    cluster_list = peaks['ID'].unique()\n",
    "    print('%i positive and %i negative clusters found.'%(\n",
    "        peaks.loc[peaks['peak_value']>0,:].shape[0],\n",
    "        peaks.loc[peaks['peak_value']<0,:].shape[0]))\n",
    "\n",
    "    for ID in cluster_list:\n",
    "        cluster_info = peaks.query('ID == @ID')\n",
    "        cluster_peak_MNI = list(cluster_info.iloc[0].loc[['X','Y','Z']].values.flatten())\n",
    "        cluster_peak_IJK, cluster_voxels, cluster_mask = expand_cluster(\n",
    "            beta_map, cluster_peak_MNI, verbose = False)\n",
    "        cluster_mask_arr = cluster_mask.get_data().astype(int)\n",
    "        if verbose:\n",
    "            print('Cluster %i, nvox = %i.'%(ID,np.sum(cluster_mask_arr[:])))\n",
    "        else:\n",
    "            print(ID, end = ',')\n",
    "        all_cluster_mask_arr += cluster_mask_arr\n",
    "\n",
    "    # Mask with extent-thresholded data\n",
    "    print('Masking...')\n",
    "    masked_beta_array = np.multiply(beta_map_arr, all_cluster_mask_arr)\n",
    "    beta_map_extthres = Nifti1Image(masked_beta_array, beta_map.affine.copy())\n",
    "\n",
    "    # Save\n",
    "    print('Writing...')\n",
    "    #     ext = '.nii' + fname.split('.nii')[1]\n",
    "    ext = '.nii'\n",
    "    out_fname = fname.split('.nii')[0] + '_ext-thr-%i'%extent_threshold + ext\n",
    "    beta_map_extthres.to_filename(out_fname)\n",
    "    print('Saved to %s.'%out_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.realpath('../../..')\n",
    "print(base_dir)\n",
    "results_dir = os.path.realpath(base_dir + '/Results/voxelwise_ISRSA/nifti')\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select run and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['ideology']\n",
    "predictors = ['scale(ideology_similarity)']\n",
    "thresholds = ['fdr-0.05']\n",
    "extent_threshold = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clust_info = pd.DataFrame(columns = \n",
    "                          ['run','model','predictor','threshold','exists','n_clust','peak_val','peak_size'])\n",
    "for run in [1,2,3]:\n",
    "    print('Run %i'%run)\n",
    "    for model in models:\n",
    "        print('Model %s'%model, end = '; ')\n",
    "        for predictor in predictors:\n",
    "            for threshold in thresholds:\n",
    "                fnames = glob.glob(results_dir + '/run-%i_model-%s/dyad_ISC_regressor-%s_beta-thr-pval-%s.nii.gz'%(\n",
    "                                    run, model, predictor, threshold))\n",
    "                if len(fnames) > 0:\n",
    "                    if len(fnames) > 1:\n",
    "                        print(\"Warning: more than 1 filename match!\")\n",
    "                    fname = fnames[0]\n",
    "                    img = nib.load(fname)\n",
    "                    clusters, peaks = get_clusters(img, extent_threshold = extent_threshold, sort_by_size = False)\n",
    "                    n_clust = peaks.shape[0]\n",
    "                    exist = True\n",
    "                    if n_clust > 0:\n",
    "                        peak_val, peak_size = [peaks.iloc[0,:][i] for i in ['peak_value','size']]\n",
    "                    else:\n",
    "                        peak_val, peak_size = [np.nan, np.nan]\n",
    "                else:\n",
    "                    n_clust = np.nan\n",
    "                    exist = False\n",
    "                to_append = pd.DataFrame([[run,model,predictor,threshold,exist,n_clust,peak_val,peak_size]],\n",
    "                                         columns = clust_info.columns)\n",
    "                clust_info = clust_info.append(to_append).reset_index(drop=True)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clust_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pull out one run/model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "clust_info = pd.DataFrame(columns = \n",
    "                          ['run','model','predictor','threshold','exists','n_clust','peak_val','peak_size'])\n",
    "run = 3\n",
    "model = 'ideology'\n",
    "threshold = 'fdr-0.05'\n",
    "predictors = ['scale(ideology_similarity)']\n",
    "\n",
    "for predictor in predictors:\n",
    "    fnames = glob.glob(results_dir + '/run-%i_model-%s/dyad_ISC_regressor-%s_beta-thr-pval-%s.nii'%(\n",
    "                        run, model, predictor, threshold))\n",
    "    if len(fnames) > 0:\n",
    "        if len(fnames) > 1:\n",
    "            print(\"Warning: more than 1 filename match!\")\n",
    "        fname = fnames[0]\n",
    "        img = nib.load(fname)\n",
    "        plot_stat_map(img, title = predictor)\n",
    "        plt.show()\n",
    "        clusters, peaks = get_clusters(img)\n",
    "        n_clust = peaks.shape[0]\n",
    "        display(peaks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
