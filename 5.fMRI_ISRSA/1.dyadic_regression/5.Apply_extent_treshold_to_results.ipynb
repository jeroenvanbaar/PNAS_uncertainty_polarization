{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob, scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nilearn, nibabel, nltools\n",
    "from nltools.data import Brain_Data\n",
    "from nilearn.plotting import plot_glass_brain, plot_stat_map\n",
    "from nilearn.image import new_img_like\n",
    "from nistats.reporting import get_clusters_table\n",
    "from nibabel.nifti1 import Nifti1Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clusters(image, stat_threshold = 0, extent_threshold = 0, sort_by_size = False, include_peaks_only = True):\n",
    "    \n",
    "    # Compute negative image\n",
    "    neg_image_arr = -(image.get_data().copy())\n",
    "    neg_image = Nifti1Image(neg_image_arr, image.affine.copy())\n",
    "    \n",
    "    # Find clusters\n",
    "    clusters = get_clusters_table(image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    clusters = clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters = get_clusters_table(neg_image, stat_threshold, cluster_threshold = extent_threshold)\n",
    "    neg_clusters = neg_clusters.rename(columns = {'Cluster ID':'ID', 'Cluster Size (mm3)':'size',\n",
    "                                          'Peak Stat':'peak_value'})\n",
    "    neg_clusters['peak_value'] = -neg_clusters['peak_value']\n",
    "    \n",
    "    # Append pos and neg\n",
    "    clusters = clusters.append(neg_clusters)\n",
    "    clusters['abs_peak_value'] = clusters['peak_value'].apply(np.abs)\n",
    "    clusters = clusters.sort_values(by='abs_peak_value', ascending = False)\n",
    "    \n",
    "    # Get peaks\n",
    "    if include_peaks_only:\n",
    "        peaks = clusters.copy()\n",
    "        peaks = peaks.loc[peaks['ID'].apply(lambda x: not str(x)[-1].isalpha()),:].reset_index(drop=True)\n",
    "        if sort_by_size:\n",
    "            peaks = peaks.sort_values(by = 'size', ascending = False).reset_index(drop=True)\n",
    "    \n",
    "    return clusters, peaks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyz_to_ijk(MNI, image):\n",
    "    return list(np.linalg.inv(image.affine[:3,:3]).dot(MNI-image.affine[:3,3]).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_cluster(image, cluster_peak_MNI, verbose = True):\n",
    "    \n",
    "    # Find IJK of peak\n",
    "    i,j,k = xyz_to_ijk(cluster_peak_MNI,image)\n",
    "    cluster_peak_IJK = [i,j,k]\n",
    "    if verbose: print('MNI: %s, IJK: %s'%(cluster_peak_MNI, cluster_peak_IJK))\n",
    "    \n",
    "    # Double check that peak value is correct\n",
    "    peakval = image.get_data()[i][j][k]\n",
    "    if verbose: print('Peak value extracted from image data array: %f'%peakval)\n",
    "    \n",
    "    # Binarize image\n",
    "    binarized = (image.get_data() != 0).astype(int)\n",
    "        \n",
    "    # Label each cluster with a different number, reserve 0 for empty voxels\n",
    "    conn_mat = np.zeros((3, 3, 3), int)  # 6-connectivity, aka NN1 or \"faces\"\n",
    "    conn_mat[1, 1, :] = 1\n",
    "    conn_mat[1, :, 1] = 1\n",
    "    conn_mat[:, 1, 1] = 1\n",
    "    label_map = scipy.ndimage.measurements.label(binarized, conn_mat)[0]\n",
    "    clust_image = nibabel.Nifti1Image(label_map, affine=image.affine)\n",
    "    \n",
    "    # Find voxels with same label as cluster peak\n",
    "    cluster_label = clust_image.get_data()[i,j,k]\n",
    "    cluster_ROI = (clust_image.get_data() == cluster_label).astype(int)\n",
    "    ROI_mask = nibabel.Nifti1Image(cluster_ROI, affine = image.affine)\n",
    "    if verbose: print('Cluster ROI located')\n",
    "    if verbose: print('Cluster size as extracted from image data array: %i voxels = %i mm^3'%(\n",
    "        sum(cluster_ROI.flatten()),sum(cluster_ROI.flatten())*8))\n",
    "    \n",
    "    return cluster_peak_IJK, cluster_ROI, ROI_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to shorten the filenames otherwise some apps like mricron cant read them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_names = {'scale(ideology_similarity)':'ideosim',\n",
    "               'ideology_pair':'party',\n",
    "               'ideology_pairWithin_con':'con',\n",
    "               'ideology_pairWithin_lib':'lib',\n",
    "               'ideology_sameWithin_group':'samegroup',\n",
    "               'joint_IUS':'IUS',\n",
    "               'joint_NFC':'NFC',\n",
    "               'dyad_ISC_regressor-':'',\n",
    "               'beta-thr-pval-':'',\n",
    "               'fdr-0.05':'fdr',\n",
    "               'ext-thr-5':'ext-5',\n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_extent_threshold(fname, extent_threshold, verbose = False, use_short_out_fname = False):\n",
    "    \n",
    "    print('Loading stat map...')\n",
    "    beta_map = nilearn.image.load_img(fname)\n",
    "    beta_map_arr = beta_map.get_data()\n",
    "\n",
    "    print('Preparing thresholded mask...')\n",
    "    all_cluster_mask_arr = beta_map_arr.copy().astype(int)\n",
    "    all_cluster_mask_arr[:] = 0\n",
    "\n",
    "    print('Counting clusters...')\n",
    "    clusters, peaks = get_clusters(beta_map, stat_threshold = 0,\n",
    "                               extent_threshold = extent_threshold, include_peaks_only = True)\n",
    "    cluster_list = peaks['ID'].unique()\n",
    "    print('%i positive and %i negative clusters found.'%(\n",
    "        peaks.loc[peaks['peak_value']>0,:].shape[0],\n",
    "        peaks.loc[peaks['peak_value']<0,:].shape[0]))\n",
    "\n",
    "    for ID in cluster_list:\n",
    "        cluster_info = peaks.query('ID == @ID')\n",
    "        cluster_peak_MNI = list(cluster_info.iloc[0].loc[['X','Y','Z']].values.flatten())\n",
    "        cluster_peak_IJK, cluster_voxels, cluster_mask = expand_cluster(\n",
    "            beta_map, cluster_peak_MNI, verbose = False)\n",
    "        cluster_mask_arr = cluster_mask.get_data().astype(int)\n",
    "        if verbose:\n",
    "            print('Cluster %i, nvox = %i.'%(ID,np.sum(cluster_mask_arr[:])))\n",
    "        else:\n",
    "            print(ID, end = ',')\n",
    "        all_cluster_mask_arr += cluster_mask_arr\n",
    "\n",
    "    # Mask with extent-thresholded data\n",
    "    print('Masking...')\n",
    "    masked_beta_array = np.multiply(beta_map_arr, all_cluster_mask_arr)\n",
    "    beta_map_extthres = Nifti1Image(masked_beta_array, beta_map.affine.copy())\n",
    "\n",
    "    # Save\n",
    "    print('Writing...')\n",
    "    #     ext = '.nii' + fname.split('.nii')[1]\n",
    "    ext = '.nii'\n",
    "    out_fname = fname.split('.nii')[0] + '_ext-thr-%i'%extent_threshold + ext\n",
    "    short_out_fname = out_fname.split('/')[-1]\n",
    "    for source,target in short_names.items():\n",
    "        short_out_fname = short_out_fname.replace(source,target)\n",
    "    short_out_fname = '/'.join(out_fname.split('/')[:-1]) + '/' + short_out_fname\n",
    "    if use_short_out_fname:\n",
    "        beta_map_extthres.to_filename(short_out_fname)\n",
    "        print('Saved to %s.'%short_out_fname)\n",
    "    else:\n",
    "        beta_map_extthres.to_filename(out_fname)\n",
    "        print('Saved to %s.'%out_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = os.path.realpath('../../..')\n",
    "print(base_dir)\n",
    "results_dir = os.path.realpath(base_dir + '/Results/voxelwise_ISRSA/nifti')\n",
    "results_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run across runs and models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = ['ideology','ideology_IUS','ideology_control','ideology_IUS_control',\n",
    "#           'party','party_IUS','ideology_party_interact','ideology_party_interact_control']\n",
    "# models = ['ideology_rerun','ideology_IUS_rerun','ideology_NFC','samegroup','samegroup_IUS']\n",
    "models = ['ideology_IUS']\n",
    "predictors = ['scale(ideology_similarity)',\n",
    "             'joint_IUS','scale(ideology_similarity)-X-joint_IUS']\n",
    "statistic = 'beta'\n",
    "thresholds = ['fdr-0.05']\n",
    "extent_threshold = 5\n",
    "use_short_out_fname = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in [3]:\n",
    "    print('Run %i'%run)\n",
    "    for model in models:\n",
    "        for predictor in predictors:\n",
    "            for threshold in thresholds:\n",
    "                fnames = glob.glob(results_dir + '/run-%i_model-%s/dyad_ISC_regressor-%s_%s-thr-pval-%s.nii.gz'%(\n",
    "                                    run, model, predictor, statistic, threshold))\n",
    "                if len(fnames) > 0:\n",
    "                    print('Files found for %s: %s at %s'%(model, predictor, threshold))\n",
    "                    if len(fnames) > 1:\n",
    "                        print(\"Warning: more than 1 filename match!\")\n",
    "                    fname = fnames[0]\n",
    "                    print(fname)\n",
    "                    apply_extent_threshold(fname, extent_threshold = extent_threshold,\n",
    "                                           verbose = True, use_short_out_fname = True)\n",
    "                    print('\\n***')\n",
    "#                 else:\n",
    "#                     print('Warning: no filename match!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
